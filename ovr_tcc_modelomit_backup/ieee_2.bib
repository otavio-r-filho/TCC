@INPROCEEDINGS{7575061, 
author={B. Ilias and S. A. A. Shukor and A. H. Adom and M. F. Ibrahim and S. Yaacob}, 
booktitle={2016 IEEE Symposium on Computer Applications Industrial Electronics (ISCAIE)}, 
title={A novel indoor mobile robot mapping with USB-16 ultrasonic sensor bank and NWA optimization algorithm}, 
year={2016}, 
pages={189-194}, 
abstract={This paper highlights on the development of a Ultrasonic Sensor Bank with sixteen pieces 40 kHz ultrasonic sensor (USB-16) mounted on hexadecagon-based plate on a mobile robot to perform real time 2D and 3D mapping. The purpose of this research is to evaluate the capability of USB-16 in providing an accurate map in terms of the walls perimeter and its shape, where the robot is located. Each wall will be scanned with USB-16 sensor bank to measure the distance between the center of sensor bank and the wall. The Homogeneous Transformation Matrix (HTM) and trigonometrically algorithm is utilized in this research as a wall mapping algorithm and is clearly explained in this paper. An optimum wall mapping algorithm was introduced to minimize measurement error. The optimum wall mapping technique named a Nominal Wall Angle (NWA) using trigonometric approach was introduced to improve the mapping accuracy. This algorithm has the capability to improve the ultrasonic mapping accuracy during the scanning process and is different from data manipulation technique like most of similar researches currently adapted. The comparison of experimental results before and after implementation of the optimization technique in different wall shape (Curve, Square, Rectangle, Triangle and Laboratory environment) will be presented in this paper. The results are very impressive, where the implementation of NWA algorithm is able to produce an accurate wall mapping compared with the actual wall size. LabVIEW software, Basic Atom and BASIC Stamp microcontroller are fully utilized to produce the real time 2D and 3D graph during the USB-16 mapping.}, 
keywords={matrix algebra;mobile robots;optimisation;HTM;NWA algorithm;NWA optimization algorithm;hexadecagon-based plate;homogeneous transformation matrix;nominal wall angle;novel indoor mobile robot mapping;optimum wall mapping algorithm;trigonometric approach;ultrasonic sensor bank;Acoustics;Laboratories;Optimization;Real-time systems;Robot sensing systems;Shape;BASIC Stamp;Basic Atom;Homogeneous transformation matrix (HTM);Indoor mapping;LabVIEW software;Mobile robot;Nominal Wall Angle (NWA) algorithm;Ultrasonic Sensor Bank (USB-16)}, 
doi={10.1109/ISCAIE.2016.7575061}, 
month={May},}
@INPROCEEDINGS{7554319, 
author={M. Jian and C. F. Zhang and F. Yan and M. Z. Tang}, 
booktitle={2016 35th Chinese Control Conference (CCC)}, 
title={A global line extraction algorithm for indoor robot mapping based on noise eliminating via similar triangles rule}, 
year={2016}, 
pages={6133-6138}, 
abstract={Robot mapping from 2D laser rangefinder data is critical to indoor autonomous mobile localization and navigation. On the basis of Split algorithm, this paper presents a similar triangles rule, which is used to quantify the random characteristics of the space position of noise points. The direction of the real line is acquired by using the statistical method to analyze the quantified data, and the noise points can be eliminated based on the actual line direction as much as possible. Finally, we split the points after denoising again and then fit lines by least square method in each two adjacent split points. Experiments show that, compared with the conventional Split-and-Merge algorithm, the proposed technique performs better on both accuracy and correctness. The process of line segments merging is avoided, and the precision and robustness of environment modeling are enhanced in the proposed algorithm.}, 
keywords={SLAM (robots);data analysis;feature extraction;image denoising;indoor navigation;least squares approximations;mobile robots;2D laser rangefinder data;actual line direction;autonomous mobile navigation;denoising;indoor autonomous mobile localization;indoor robot mapping;least square method;line extraction algorithm;line segments merging;noise elimination;quantified data analysis;similar triangles rule;space position;split algorithm;split-and-merge algorithm;statistical method;Data mining;Feature extraction;Laser noise;Measurement by laser beam;Noise reduction;Robots;Two dimensional displays;Split algorithm;least square method;line extraction;robot mapping;similar triangles rule}, 
doi={10.1109/ChiCC.2016.7554319}, 
month={July},}
@INPROCEEDINGS{7501155, 
author={P. Olivka and M. Mihola and P. Novák and T. Kot and J. Babjak}, 
booktitle={2016 17th International Carpathian Control Conference (ICCC)}, 
title={The 3D laser range finder design for the navigation and mapping for the coal mine robot}, 
year={2016}, 
pages={533-538}, 
abstract={This article describes the construction of the 3D laser range finder (LRF) for the coal mine robot. The construction is based on our practical experiences with previous indoor 3D LRF design. The coal mine environment is very dirty. It is necessary to keep in mind this heavy working condition during the whole design process. The process of design started with definition of requirements. This specification is followed by selection of suitable parts and the dynamic analysis of a selected actuator. The suitable housing was designed for spatially arranged internal parts and by the Rapid Prototyping method was made the fully functional 3D LRF prototype. Finally are presented results from the 3D LRF testing conducted in the real underground environment.}, 
keywords={coal;control engineering computing;industrial robots;laser ranging;mining;path planning;rapid prototyping (industrial);robot vision;3D laser range finder design;actuator dynamic analysis;coal mine robot mapping;coal mine robot navigation;indoor 3D LRF design;rapid prototyping;underground environment;Coal mining;Frequency measurement;Prototypes;Robot sensing systems;Servomotors;Three-dimensional displays;3D Mapping;Laser Range Finder;Point Cloud;Positioning Sensor;Rapid Prototyping;Servo;TeleRescuer}, 
doi={10.1109/CarpathianCC.2016.7501155}, 
month={May},}
@INPROCEEDINGS{7443427, 
author={N. Jain and Y. P. Kumar and K. S. Nagla}, 
booktitle={2015 Annual IEEE India Conference (INDICON)}, 
title={Corner extraction from indoor environment for mobile robot mapping}, 
year={2015}, 
pages={1-6}, 
abstract={In order to construct more accurate map of the environment, it is essential to extract the key features of environment using appropriate sensor. Sensor plays a fundamental role in the detection of key features. For example to extract the corners from the mobile robot's indoor environment sonar sensor is not appropriate due to Specular reflections and for glass like features laser sensor will provide erroneous result but for corners it will provide more accurate and reliable results. In complex indoor environment identification of concave and convex corner not only reduces the navigational complexity but also reduces the decision time for autonomous mobile robots. This paper addresses the new architecture for corner feature extraction from indoor environment. Second Section of the paper deals with the filtration of the raw information and perform clustering of the laser range information based on the resolution of laser range finder and concerned environment. Third section deals with identification of concave and convex corners in the environment using the laser range finder. Experimentation carried out shows 6.5% improvement in corners detection for the indoor environment as compared to the conventional approach. The computational time is also reduced up to reasonable extent.}, 
keywords={feature extraction;mobile robots;object detection;path planning;robot vision;sensors;concave corner identification;convex corner identification;corner extraction;feature detection;feature extraction;laser range finder;laser range information;laser sensor;mobile robot mapping;Indoor environments;Mobile communication;Navigation;Robot kinematics;Robot sensing systems;Sonar;Autonomous robot navigation;Identification of corners;Laser Range Finder;Localization;Mapping}, 
doi={10.1109/INDICON.2015.7443427}, 
month={Dec},}
@INPROCEEDINGS{7260590, 
author={D. Jianhao and L. Meiqin and S. Weihua}, 
booktitle={Control Conference (CCC), 2015 34th Chinese}, 
title={Efficient exploration for real-time robot indoor 3D mapping}, 
year={2015}, 
pages={6078-6083}, 
abstract={Environmental mapping is an important problem for autonomous robots. In this paper, we study the problem of how to efficiently explore an unknown environment to build a 3D map. A Robotic 3D Mapping (RoM) system is developed which enables efficient exploration for real-time robot mapping. The 3D information comes from a RGB-D camera on the pan-tilt unit mounted on a Pioneer mobile robot base. In the mapping process, the camera pose is estimated based on a Bayesian framework combining the robot motion and visual features. The map is updated in real time and converted into the 3D occupancy map with new observed data. An efficient exploration strategy is proposed using the resulted 3D occupancy map. A multi-layer structure is applied to filter the viewpoints to a small set and the next best viewpoint is determined by maximizing the expected information gain. Experiments are conducted in an indoor environment and the results show that the robot is able to perform efficient, autonomous exploration to cover the unknown areas and build the map.}, 
keywords={Bayes methods;cameras;feature extraction;image colour analysis;indoor navigation;mobile robots;path planning;pose estimation;real-time systems;robot vision;3D information;3D occupancy map;Bayesian framework;Pioneer mobile robot base;RGB-D camera;RoM system;autonomous robots;camera pose estimation;environmental mapping;multilayer structure;pan-tilt unit;real-time robot indoor 3D mapping system;robot motion;visual features;Cameras;Mobile robots;Robot vision systems;Three-dimensional displays;Autonomous Exploration;Indoor 3D Mapping;Robot Platform}, 
doi={10.1109/ChiCC.2015.7260590}, 
month={July},}
@INPROCEEDINGS{7162421, 
author={R. Xiaogang and W. Danyang and P. Tao}, 
booktitle={The 27th Chinese Control and Decision Conference (2015 CCDC)}, 
title={Autonomous mapping for robot based on monocular vision and DGSOM algorithm}, 
year={2015}, 
pages={2899-2902}, 
abstract={Aiming at the problems in unknown environment for mobile robots map building, a method combined monocular vision and DGSOM(Dynamic Growing-SOM) Algorithm is proposed. The method first uses a monocular camera to collect environment images, after treatment with monocular vision processing technology, environmental information samples for DGSOM algorithm are obtained from image information, and then they can be used as neural network training samples, thus the topologic map that describes the environment information is generated with a few SOFM neurons. The experimental result shows that autonomous mapping for robot using a combination of monocular vision and DGSOM algorithm is feasible, and the robot can realize environment mapping automatically.}, 
keywords={cameras;mobile robots;robot vision;self-organising feature maps;DGSOM algorithm;autonomous robot mapping;dynamic growing-self-organizing feature map algorithm;environment image collection;environment mapping;environmental information samples;image information;mobile robots;monocular camera;monocular vision processing technology;neural network training samples;topologic map;Cameras;Mobile robots;Neurons;Process control;Service robots;Training;DGSOM;Robot;environment mapping;monocular vision}, 
doi={10.1109/CCDC.2015.7162421}, 
ISSN={1948-9439}, 
month={May},}
@INPROCEEDINGS{7101614, 
author={P. Koch and S. May and M. Schmidpeter and M. Kühn and C. Pfitzner and C. Merkl and R. Koch and M. Fees and J. Martin and A. Nüchter}, 
booktitle={Autonomous Robot Systems and Competitions (ICARSC), 2015 IEEE International Conference on}, 
title={Multi-robot Localization and Mapping Based on Signed Distance Functions}, 
year={2015}, 
pages={77-82}, 
abstract={This publication describes a 2D Simultaneous Localization and Mapping approach applicable to multiple mobile robots. The presented strategy uses data of 2D LIDAR sensors to build a dynamic representation based on Signed Distance Functions. A multi-threaded software architecture performs registration and data integration in parallel allowing for drift-reduced pose estimation of multiple robots. Experiments are provided demonstrating the application with single and multiple robot mapping using simulated data, public accessible recorded data as well as two actual robots operating in a comparably large area.}, 
keywords={SLAM (robots);control engineering computing;data integration;mobile robots;multi-robot systems;optical radar;pose estimation;radar imaging;software architecture;2D LIDAR sensors;2D simultaneous localization and mapping approach;data integration;drift-reduced pose estimation;dynamic representation;multiple mobile robots;multirobot localization;multirobot mapping;multithreaded software architecture;signed distance functions;Buildings;Computer architecture;Robot kinematics;Simultaneous localization and mapping;Mobile Robotics;Multi-Robot;Rescue Robotics;SLAM}, 
doi={10.1109/ICARSC.2015.18}, 
month={April},}